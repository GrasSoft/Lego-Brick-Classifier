{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b231c9c2-16f2-4c94-8ef6-00b0556a3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score,  confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Models import CustomResNet34, CustomResNet18, CustomResNet50\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b626361-7282-456a-b5c7-8f05f9d9e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/gras/Documents/University/ComputerVision/occluded\"\n",
    "folder_name = \"resnet34_occluded_occluded\"\n",
    "model34_path = \"/home/gras/Documents/University/ComputerVision/resnet34-noocclusion.pth\"\n",
    "model34_occluded_path = \"/home/gras/Documents/University/ComputerVision/resnet34-occlusion_1.pth\"\n",
    "model34_colour_path = \"/home/gras/Documents/University/ComputerVision/resnet34-colour.pth\"\n",
    "model18_path = \"/home/gras/Documents/University/ComputerVision/resnet18-noocclusion.pth\"\n",
    "model50_path = \"/home/gras/Documents/University/ComputerVision/resnet50-noocclusion.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e532afd0-7f12-41b5-a579-1a010f3570a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a directory\n",
    "def create_directory(path, folder_name):\n",
    "    directory = os.path.join(path, folder_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "# Function to save metrics in a text file\n",
    "def save_metrics_to_file(metrics, directory):\n",
    "    text_path = os.path.join(directory, 'metrics.txt')\n",
    "    with open(text_path, 'w') as f:\n",
    "        for metric, value in metrics.items():\n",
    "            f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Function to save confusion matrix as an image\n",
    "def save_confusion_matrix_image(cm, classes, directory):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    image_path = os.path.join(directory, 'confusion_matrix.png')\n",
    "\n",
    "    # Convert confusion matrix to a DataFrame\n",
    "    df_confusion_matrix = pd.DataFrame(cm)\n",
    "\n",
    "    csv_path = os.path.join(directory, \"confusion_matrix.csv\")\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    df_confusion_matrix.to_csv(csv_path, index=False)\n",
    "\n",
    "    \n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823aed95-46a4-41b4-b101-2075176c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main script\n",
    "\n",
    "def save_metrics(path, folder_name, y_true, y_pred):\n",
    "    # Create directory\n",
    "    directory = create_directory(path, folder_name)\n",
    "\n",
    "    # Convert lists or arrays to numpy arrays if not already\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = [str(i) for i in range(200)]  # List of class labels\n",
    "    save_confusion_matrix_image(cm, classes, directory)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    # Save metrics to file\n",
    "    save_metrics_to_file(metrics, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981bafb5-614f-4b31-8b88-2af27da1e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing transformation\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),    # Resize the image to 224x224 pixels\n",
    "    transforms.Grayscale(num_output_channels = 3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "\n",
    "# Load the dataset and apply transformation\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c8ed4f-0ecc-472b-99ab-b9da697b8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels\n",
    "targets = np.array(dataset.targets)\n",
    "\n",
    "small_targets = dataset.targets\n",
    "# Stratified split\n",
    "train_indices, test_indices = train_test_split(np.arange(len(small_targets)), test_size=0.2, stratify=small_targets, random_state=123)\n",
    "\n",
    "# Create PyTorch subsets\n",
    "# train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbf475f-f319-4509-966e-5689ac84d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model34_occluded_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61fc8cf-6cdd-4783-ae93-73fcb29fa04e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 6400 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m y_real\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m y_pred\u001b[38;5;241m.\u001b[39mappend(predicted)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 6400 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define empty lists to store accuracy and number of images tested\n",
    "test_accuracies = []\n",
    "num_images_tested = []\n",
    "\n",
    "y_pred = []\n",
    "y_real = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for calculating accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over the test set\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader, 1):\n",
    "        # Move inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y_real.append(labels)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        y_pred.append(predicted)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Store accuracy and number of images tested\n",
    "        test_accuracies.append(accuracy)\n",
    "        num_images_tested.append(i * test_loader.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3ea3f-6eef-430d-aa32-e7421d963bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all tensors in the lists to form single tensors\n",
    "y_real = torch.cat(y_real)\n",
    "y_pred = torch.cat(y_pred)\n",
    "\n",
    "# Move tensors to CPU and convert to NumPy arrays\n",
    "y_real = y_real.cpu().numpy()\n",
    "y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "save_metrics(path=\"./\", folder_name=folder_name, y_true=y_real, y_pred=y_pred)\n",
    "\n",
    "\n",
    "# Plot the accuracy curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(num_images_tested, test_accuracies, marker='o')\n",
    "plt.title('Test Accuracy vs Number of Images Tested')\n",
    "# plt.xlabel('Number of Images Tested')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ca8ee-b649-4d81-a5de-9e98f7dee3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
